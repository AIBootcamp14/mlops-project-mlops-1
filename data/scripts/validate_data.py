# data/scripts/validate_data.py
import pandas as pd
import numpy as np
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any

class DataValidator:
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.setup_logging()
        self.validation_rules = self.load_validation_rules()
        
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / 'data_validation.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_validation_rules(self) -> Dict:
        """ë°ì´í„° ê²€ì¦ ê·œì¹™ ì •ì˜"""
        return {
            'required_columns': ['target', 'text'],
            'target_values': [0, 1],
            'min_text_length': 1,
            'max_text_length': 5000,
            'min_dataset_size': 100,
            'target_balance_threshold': 0.1,  # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì„ê³„ê°’ (10% ë¯¸ë§Œì´ë©´ ê²½ê³ )
            'duplicate_threshold': 0.05,  # ì¤‘ë³µ ë°ì´í„° ì„ê³„ê°’ (5% ì´ìƒì´ë©´ ê²½ê³ )
        }
    
    def validate_schema(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
        results = {
            'passed': True,
            'errors': [],
            'warnings': []
        }
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = self.validation_rules['required_columns']
        missing_cols = set(required_cols) - set(df.columns)
        if missing_cols:
            results['passed'] = False
            results['errors'].append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
        
        # ë°ì´í„° íƒ€ì… í™•ì¸
        if 'target' in df.columns:
            if not pd.api.types.is_numeric_dtype(df['target']):
                results['passed'] = False
                results['errors'].append("target ì»¬ëŸ¼ì´ ìˆ«ìí˜•ì´ ì•„ë‹™ë‹ˆë‹¤")
        
        if 'text' in df.columns:
            if not pd.api.types.is_object_dtype(df['text']):
                results['warnings'].append("text ì»¬ëŸ¼ì´ ë¬¸ìì—´ íƒ€ì…ì´ ì•„ë‹™ë‹ˆë‹¤")
        
        return results
    
    def validate_data_quality(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
        results = {
            'passed': True,
            'errors': [],
            'warnings': [],
            'metrics': {}
        }
        
        # ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸
        if len(df) < self.validation_rules['min_dataset_size']:
            results['passed'] = False
            results['errors'].append(f"ë°ì´í„°ì…‹ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {len(df)} < {self.validation_rules['min_dataset_size']}")
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        null_counts = df.isnull().sum()
        if null_counts.sum() > 0:
            results['warnings'].append(f"ê²°ì¸¡ì¹˜ ë°œê²¬: {null_counts.to_dict()}")
        
        # target ê°’ ë²”ìœ„ í™•ì¸
        if 'target' in df.columns:
            invalid_targets = ~df['target'].isin(self.validation_rules['target_values'])
            if invalid_targets.sum() > 0:
                results['passed'] = False
                results['errors'].append(f"ì˜ëª»ëœ target ê°’ {invalid_targets.sum()}ê°œ ë°œê²¬")
            
            # í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸
            target_dist = df['target'].value_counts(normalize=True)
            min_class_ratio = target_dist.min()
            if min_class_ratio < self.validation_rules['target_balance_threshold']:
                results['warnings'].append(f"ì‹¬ê°í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜•: ìµœì†Œ í´ë˜ìŠ¤ ë¹„ìœ¨ {min_class_ratio:.3f}")
            
            results['metrics']['target_distribution'] = {int(k): int(v) for k, v in target_dist.items()}
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸
        if 'text' in df.columns:
            text_lengths = df['text'].str.len()
            
            # ë¹ˆ í…ìŠ¤íŠ¸ í™•ì¸
            empty_texts = text_lengths < self.validation_rules['min_text_length']
            if empty_texts.sum() > 0:
                results['warnings'].append(f"ë¹ˆ í…ìŠ¤íŠ¸ {empty_texts.sum()}ê°œ ë°œê²¬")
            
            # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ í™•ì¸
            long_texts = text_lengths > self.validation_rules['max_text_length']
            if long_texts.sum() > 0:
                results['warnings'].append(f"ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ {long_texts.sum()}ê°œ ë°œê²¬")
            
            results['metrics']['text_length_stats'] = {
                'mean': float(text_lengths.mean()),
                'median': float(text_lengths.median()),
                'min': int(text_lengths.min()),
                'max': int(text_lengths.max()),
                'std': float(text_lengths.std())
            }
        
        # ì¤‘ë³µ ë°ì´í„° í™•ì¸
        if 'text' in df.columns:
            duplicate_count = df['text'].duplicated().sum()
            duplicate_ratio = duplicate_count / len(df)
            
            if duplicate_ratio > self.validation_rules['duplicate_threshold']:
                results['warnings'].append(f"ë†’ì€ ì¤‘ë³µ ë¹„ìœ¨: {duplicate_ratio:.3f} ({duplicate_count}ê°œ)")
            
            results['metrics']['duplicate_ratio'] = float(duplicate_ratio)
            results['metrics']['duplicate_count'] = int(duplicate_count)
        
        return results
    
    def validate_preprocessing_consistency(self, original_df: pd.DataFrame, processed_df: pd.DataFrame) -> Dict[str, Any]:
        """ì „ì²˜ë¦¬ ì¼ê´€ì„± ê²€ì¦"""
        results = {
            'passed': True,
            'errors': [],
            'warnings': [],
            'metrics': {}
        }
        
        # ë°ì´í„° ì†ì‹¤ í™•ì¸
        original_size = len(original_df)
        processed_size = len(processed_df)
        data_loss_ratio = (original_size - processed_size) / original_size
        
        if data_loss_ratio > 0.1:  # 10% ì´ìƒ ë°ì´í„° ì†ì‹¤ì‹œ ê²½ê³ 
            results['warnings'].append(f"ë†’ì€ ë°ì´í„° ì†ì‹¤ë¥ : {data_loss_ratio:.3f}")
        
        results['metrics']['data_loss_ratio'] = float(data_loss_ratio)
        results['metrics']['original_size'] = int(original_size)
        results['metrics']['processed_size'] = int(processed_size)
        
        # target ë¶„í¬ ì¼ê´€ì„± í™•ì¸
        if 'target' in original_df.columns and 'target' in processed_df.columns:
            orig_dist = original_df['target'].value_counts(normalize=True).sort_index()
            proc_dist = processed_df['target'].value_counts(normalize=True).sort_index()
            
            dist_diff = abs(orig_dist - proc_dist).max()
            if dist_diff > 0.05:  # 5% ì´ìƒ ë¶„í¬ ë³€í™”ì‹œ ê²½ê³ 
                results['warnings'].append(f"target ë¶„í¬ ë³€í™”: ìµœëŒ€ ì°¨ì´ {dist_diff:.3f}")
            
            results['metrics']['target_distribution_change'] = float(dist_diff)
        
        return results
    
    def run_full_validation(self, data_path: str) -> Dict[str, Any]:
        """ì „ì²´ ê²€ì¦ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("=== ë°ì´í„° ê²€ì¦ ì‹œì‘ ===")
        
        validation_report = {
            'timestamp': datetime.now().isoformat(),
            'data_path': data_path,
            'overall_passed': True,
            'schema_validation': {},
            'quality_validation': {},
            'consistency_validation': {},
            'summary': {}
        }
        
        try:
            # ë°ì´í„° ë¡œë“œ
            df = pd.read_csv(data_path)
            self.logger.info(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
            
            # 1. ìŠ¤í‚¤ë§ˆ ê²€ì¦
            schema_results = self.validate_schema(df)
            validation_report['schema_validation'] = schema_results
            if not schema_results['passed']:
                validation_report['overall_passed'] = False
            
            # 2. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
            quality_results = self.validate_data_quality(df)
            validation_report['quality_validation'] = quality_results
            if not quality_results['passed']:
                validation_report['overall_passed'] = False
            
            # 3. ì›ë³¸ ë°ì´í„°ì™€ ë¹„êµ (ì „ì²˜ë¦¬ëœ ë°ì´í„°ì¸ ê²½ìš°)
            raw_data_path = 'data/spam.csv'
            if Path(raw_data_path).exists() and 'processed' in data_path:
                try:
                    original_df = pd.read_csv(raw_data_path, encoding='latin-1')
                    # ì»¬ëŸ¼ ì •ë¦¬ (ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë°©ì‹)
                    if len(original_df.columns) >= 2:
                        original_df = original_df.iloc[:, :2].copy()
                        original_df.columns = ['target', 'text']
                        original_df['target'] = original_df['target'].map({'ham': 0, 'spam': 1}).fillna(original_df['target'])
                        original_df.dropna(subset=['target'], inplace=True)
                        original_df['target'] = original_df['target'].astype(int)
                    
                    consistency_results = self.validate_preprocessing_consistency(original_df, df)
                    validation_report['consistency_validation'] = consistency_results
                    if not consistency_results['passed']:
                        validation_report['overall_passed'] = False
                        
                except Exception as e:
                    self.logger.warning(f"ì›ë³¸ ë°ì´í„°ì™€ ë¹„êµ ì‹¤íŒ¨: {e}")
            
            # 4. ìš”ì•½ ìƒì„±
            total_errors = (len(schema_results.get('errors', [])) + 
                          len(quality_results.get('errors', [])) + 
                          len(validation_report['consistency_validation'].get('errors', [])))
            
            total_warnings = (len(schema_results.get('warnings', [])) + 
                            len(quality_results.get('warnings', [])) + 
                            len(validation_report['consistency_validation'].get('warnings', [])))
            
            validation_report['summary'] = {
                'total_errors': int(total_errors),
                'total_warnings': int(total_warnings),
                'data_shape': list(df.shape),  # tupleì„ listë¡œ ë³€í™˜
                'validation_status': 'PASSED' if validation_report['overall_passed'] else 'FAILED'
            }
            
            # 5. ë¦¬í¬íŠ¸ ì €ì¥
            report_path = Path('data/processed/validation_report.json')
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(validation_report, f, indent=2, ensure_ascii=False)
            
            # 6. ë¡œê·¸ ì¶œë ¥
            self.logger.info("=== ê²€ì¦ ê²°ê³¼ ìš”ì•½ ===")
            self.logger.info(f"ìƒíƒœ: {validation_report['summary']['validation_status']}")
            self.logger.info(f"ì˜¤ë¥˜: {total_errors}ê°œ")
            self.logger.info(f"ê²½ê³ : {total_warnings}ê°œ")
            self.logger.info(f"ë°ì´í„° í¬ê¸°: {df.shape}")
            
            if total_errors > 0:
                self.logger.error("âŒ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨!")
                for section in ['schema_validation', 'quality_validation', 'consistency_validation']:
                    for error in validation_report.get(section, {}).get('errors', []):
                        self.logger.error(f"  - {error}")
            else:
                self.logger.info("âœ… ë°ì´í„° ê²€ì¦ í†µê³¼!")
            
            if total_warnings > 0:
                self.logger.warning(f"âš ï¸  {total_warnings}ê°œ ê²½ê³  ë°œê²¬:")
                for section in ['schema_validation', 'quality_validation', 'consistency_validation']:
                    for warning in validation_report.get(section, {}).get('warnings', []):
                        self.logger.warning(f"  - {warning}")
            
            return validation_report
            
        except Exception as e:
            self.logger.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            validation_report['overall_passed'] = False
            validation_report['error'] = str(e)
            return validation_report


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    validator = DataValidator()
    
    # ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦
    processed_files = [
        'data/processed/train_data_latest.csv',
        'data/processed/test_data_latest.csv',
        'data/processed/processed_data_latest.csv'
    ]
    
    results = {}
    for file_path in processed_files:
        if Path(file_path).exists():
            print(f"\nğŸ” {file_path} ê²€ì¦ ì¤‘...")
            results[file_path] = validator.run_full_validation(file_path)
        else:
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {file_path}")
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ“Š ì „ì²´ ê²€ì¦ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    for file_path, result in results.items():
        status = "âœ… PASSED" if result['overall_passed'] else "âŒ FAILED"
        errors = result['summary']['total_errors']
        warnings = result['summary']['total_warnings']
        print(f"{Path(file_path).name}: {status} (ì˜¤ë¥˜: {errors}, ê²½ê³ : {warnings})")


if __name__ == "__main__":
    main()